{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/olistbr/marketing-funnel-olist\n",
      "Tamanho esperado (em bytes): 875188\n",
      "Tamanho do arquivo baixado (em bytes): 1579024\n",
      "Aviso: o tamanho dos arquivos baixados não corresponde ao tamanho esperado.\n",
      "Dataset salvo em: ../data/marketing-funnel-olist_2018-11-16/marketing-funnel-olist_2018-11-16.csv\n",
      "Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
      "Tamanho esperado (em bytes): 126186995\n",
      "Tamanho do arquivo baixado (em bytes): 131964133\n",
      "Aviso: o tamanho dos arquivos baixados não corresponde ao tamanho esperado.\n",
      "Dataset salvo em: ../data/brazilian-ecommerce_2021-10-01/brazilian-ecommerce_2021-10-01.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from datetime import datetime\n",
    "\n",
    "class KaggleDatasetDownloader:\n",
    "    def __init__(self, kaggle_json_path='kaggle.json'):\n",
    "        # Carregar as credenciais do Kaggle a partir do arquivo JSON\n",
    "        with open(kaggle_json_path, 'r') as file:\n",
    "            self.kaggle_credentials = json.load(file)\n",
    "        self.username = self.kaggle_credentials['username']\n",
    "        self.key = self.kaggle_credentials['key']\n",
    "        \n",
    "        # Inicializar a API do Kaggle\n",
    "        self.api = KaggleApi()\n",
    "        self.api.authenticate()\n",
    "    \n",
    "    def get_dataset_metadata(self, dataset_id):\n",
    "        # Configurar a URL do metadado do dataset\n",
    "        metadata_url = f'https://www.kaggle.com/api/v1/datasets/view/{dataset_id}'\n",
    "        # Fazer a requisição para obter metadados do dataset\n",
    "        response = requests.get(metadata_url, auth=(self.username, self.key))\n",
    "        # Verificar se a requisição foi bem-sucedida\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Erro ao obter metadados para {dataset_id}: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    \n",
    "    def download_dataset(self, dataset_id, base_folder):\n",
    "        # Baixar o dataset\n",
    "        self.api.dataset_download_files(dataset_id, path=base_folder, unzip=True)\n",
    "    \n",
    "    def verify_download(self, expected_size, base_folder):\n",
    "        # Verificar o tamanho dos arquivos baixados\n",
    "        downloaded_file_size = sum(\n",
    "            os.path.getsize(os.path.join(base_folder, f)) for f in os.listdir(base_folder)\n",
    "        )\n",
    "        print(\"Tamanho esperado (em bytes):\", expected_size)\n",
    "        print(\"Tamanho do arquivo baixado (em bytes):\", downloaded_file_size)\n",
    "        \n",
    "        # Comparar tamanhos e exibir o resultado\n",
    "        if downloaded_file_size == expected_size:\n",
    "            print(\"Download completo: o tamanho dos arquivos baixados corresponde ao tamanho esperado.\")\n",
    "        else:\n",
    "            print(\"Aviso: o tamanho dos arquivos baixados não corresponde ao tamanho esperado.\")\n",
    "    \n",
    "    def rename_main_file(self, base_folder, update_date, dataset_name):\n",
    "        # Nomear o arquivo principal com a data da última atualização\n",
    "        main_file_name = f'{dataset_name}_{update_date}.csv'\n",
    "        main_file_path = os.path.join(base_folder, main_file_name)\n",
    "        \n",
    "        # Salvar um dos arquivos baixados como exemplo\n",
    "        csv_files = [file for file in os.listdir(base_folder) if file.endswith(\".csv\")]\n",
    "        if csv_files:\n",
    "            os.rename(os.path.join(base_folder, csv_files[0]), main_file_path)\n",
    "            print(f\"Dataset salvo em: {main_file_path}\")\n",
    "        else:\n",
    "            print(\"Nenhum arquivo CSV encontrado para renomear.\")\n",
    "    \n",
    "    def process_dataset(self, dataset_id):\n",
    "        metadata = self.get_dataset_metadata(dataset_id)\n",
    "        if not metadata:\n",
    "            return\n",
    "        \n",
    "        # Obter informações de interesse\n",
    "        title = metadata['title']\n",
    "        description = metadata['subtitle']\n",
    "        last_updated = metadata['lastUpdated']\n",
    "        expected_size = metadata['totalBytes']\n",
    "        \n",
    "        # Converter a data de última atualização para um formato utilizável\n",
    "        update_date = datetime.strptime(last_updated, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime('%Y-%m-%d')\n",
    "    \n",
    "        # Configurar as pastas e arquivos com base na data de atualização\n",
    "        dataset_name = dataset_id.split('/')[-1]\n",
    "        base_folder = f'../data/{dataset_name}_{update_date}'\n",
    "        os.makedirs(base_folder, exist_ok=True)\n",
    "        \n",
    "        # Baixar o dataset\n",
    "        self.download_dataset(dataset_id, base_folder)\n",
    "        \n",
    "        # Verificar o download\n",
    "        self.verify_download(expected_size, base_folder)\n",
    "        \n",
    "        # Renomear o arquivo principal\n",
    "        self.rename_main_file(base_folder, update_date, dataset_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_ids = ['olistbr/marketing-funnel-olist', 'olistbr/brazilian-ecommerce']\n",
    "    downloader = KaggleDatasetDownloader()\n",
    "    for dataset_id in dataset_ids:\n",
    "        downloader.process_dataset(dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-slugify in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from kaggle) (2.2.3)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/guilherme-carvalho/Documents/projects/challenge-gcp-brazilizan-market-data/venv/lib/python3.12/site-packages (from requests->kaggle) (3.10)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=f784df9bc738bd9115644c0205e660e587ebd29517cabda7e04877553f4d121c\n",
      "  Stored in directory: /home/guilherme-carvalho/.cache/pip/wheels/46/d2/26/84d0a1acdb9c6baccf7d28cf06962ec80529fe1ad938489983\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, tqdm, bleach, kaggle\n",
      "Successfully installed bleach-6.2.0 kaggle-1.6.17 tqdm-4.67.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
